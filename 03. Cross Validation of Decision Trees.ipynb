{"nbformat":4,"nbformat_minor":0,"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.7.4"},"colab":{"name":"03. Cross Validation of Decision Trees.ipynb","provenance":[],"collapsed_sections":[]}},"cells":[{"cell_type":"markdown","metadata":{"id":"5soGuirloNgq"},"source":["# Computational Astrophysics 2021\n","---\n","## Eduard Larrañaga\n","\n","Observatorio Astronómico Nacional\\\n","Facultad de Ciencias\\\n","Universidad Nacional de Colombia\n","\n","---"]},{"cell_type":"markdown","metadata":{"id":"Ff4KTapaoNgx"},"source":["## 03. Cross-validation of Decision Trees\n","### About this notebook\n","\n","In this worksheet we will introduce the cross-validation of decision trees.\n","\n","---"]},{"cell_type":"markdown","metadata":{"id":"Y85Y_aIb8meo"},"source":["So far, we have used the median of the differences between the prediction and the target values to validate the decision tree model. This method, in which  we split the data in two sets (train and test), is known as **hold-out validation**  and it is the most basic form of validation. The measured accuracy (median of differences) will depend on how the data is splitted into subsets.\n","\n","\n","Now, we will introduce a better validation method, called **k-fold cross-validation**. This is similar to hold-out except that we split the data into k-subsets and we train and test the model k-times, using different combinations of the subsets and recording the accuracy each time (i.e. we perform the hold-out validation k times). \n","\n","In practice, each time we use a different combination of k-1 subsets to train the model and the final kth subset to test. Then, we take the average of the k accuracy measurements to be the overall accuracy of the the model.\n","\n","In this worksheet we will use the same dataset of galaxies considered in previous worksheets. However, we will also estimate how accurate is the model when applied to Quasi-Stellar Objects (QSOs) compared with other galaxies. As you may know, QSOs are galaxies that have an Active Galactic Nucleus (AGN), which makes the galaxy brighter and therefore, they are detectable with the SDSS instruments at much higher redshifts."]},{"cell_type":"markdown","metadata":{"id":"cn0RkhCyHfEO"},"source":["### Loading the Data\n","\n","As before, we will use the dataset provided as a NumPy strctured array in a binary format (.npy) called 'sdss_galaxy_colors.npy'. \n"]},{"cell_type":"code","metadata":{"id":"z2_uSWSg5VRk"},"source":["import numpy as np"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"Ob2DGMZ1o7Dp"},"source":["path='' #Define an empty string to use in case of local working"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"W9lFN5Fho-ei","executionInfo":{"status":"ok","timestamp":1612141645150,"user_tz":300,"elapsed":20323,"user":{"displayName":"Eduard Alexis Larranaga","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GgCVABzEgj-rCdyxWa29RnA0kIYUCXAaVbnRYOEhQ=s64","userId":"04402438389940282602"}},"outputId":"88c78ae0-f3c4-4f03-8438-f8171ec87223"},"source":["# Working with google colab needs to mount the Google Drive\n","from google.colab import drive\n","drive.mount('/content/drive')"],"execution_count":null,"outputs":[{"output_type":"stream","text":["Mounted at /content/drive\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"18nqDWVKpGb7"},"source":["# we define the path to the files\n","path = '/content/drive/MyDrive/Colab Notebooks/CA2021/11. Decision Trees/presentation/'"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"t00prl26IXxz","executionInfo":{"status":"ok","timestamp":1612141751866,"user_tz":300,"elapsed":446,"user":{"displayName":"Eduard Alexis Larranaga","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GgCVABzEgj-rCdyxWa29RnA0kIYUCXAaVbnRYOEhQ=s64","userId":"04402438389940282602"}},"outputId":"e0aa12a1-69a1-4b24-b329-457e4bdc358e"},"source":["data = np.load(path+'sdss_galaxy_colors.npy')\n","data"],"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["array([(19.84132, 19.52656, 19.46946, 19.17955, 19.10763, b'QSO', 0.539301  , 6.543622e-05),\n","       (19.86318, 18.66298, 17.84272, 17.38978, 17.14313, b'GALAXY', 0.1645703 , 1.186625e-05),\n","       (19.97362, 18.31421, 17.47922, 17.0744 , 16.76174, b'GALAXY', 0.04190006, 2.183788e-05),\n","       ...,\n","       (19.82667, 18.10038, 17.16133, 16.5796 , 16.19755, b'GALAXY', 0.0784592 , 2.159406e-05),\n","       (19.98672, 19.75385, 19.5713 , 19.27739, 19.25895, b'QSO', 1.567295  , 4.505933e-04),\n","       (18.00024, 17.80957, 17.77302, 17.72663, 17.7264 , b'QSO', 0.4749449 , 6.203324e-05)],\n","      dtype=[('u', '<f8'), ('g', '<f8'), ('r', '<f8'), ('i', '<f8'), ('z', '<f8'), ('spec_class', 'S6'), ('redshift', '<f8'), ('redshift_err', '<f8')])"]},"metadata":{"tags":[]},"execution_count":7}]},{"cell_type":"markdown","metadata":{"id":"C7pkVeizIyj5"},"source":["In this kind of data structure, the `dtype` attribute corresponds to the name of the features. For our example, we identify the following:\n","\n","| dtype | Feature|\n","|:-:|:-:|\n","|`u` |u band filter|\n","|`g` |g band filter|\n","|`r` |r band filter|\n","|`i` |i band filter|\n","|`z` |z band filter|\n","|`spec_class` |spectral class|\n","|`redshift` |redshift|\n","|`redshift_err` |redshift error|\n"]},{"cell_type":"markdown","metadata":{"id":"ca9ZEeaNK8Vh"},"source":["The number of samples (galaxies) in this dataset is"]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"8JHyXtPlK6Hs","executionInfo":{"status":"ok","timestamp":1612142762690,"user_tz":300,"elapsed":536,"user":{"displayName":"Eduard Alexis Larranaga","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GgCVABzEgj-rCdyxWa29RnA0kIYUCXAaVbnRYOEhQ=s64","userId":"04402438389940282602"}},"outputId":"12892e14-8457-4cd4-d2a9-4befaa94a8c6"},"source":["n = data.size\n","n"],"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["50000"]},"metadata":{"tags":[]},"execution_count":16}]},{"cell_type":"markdown","metadata":{"id":"geu4TFRioNgx"},"source":["In order to implement the decision tree, we will use the functions defined in the previous worksheet to define the features (4 color indices) and the targets (redshift)"]},{"cell_type":"code","metadata":{"id":"Q53oIok9eCgL"},"source":["# Function returning the 4 color indices and the redshifts\n","\n","features, targets = ...\n"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"3DjjbFANBHcD"},"source":["### K-Fold\n","\n","We will use the `sklearn.model_selection.KFold` function is designed to split the data into training and testing subsets. It does this by offering an iterable object that can be initialised with\n","\n","```\n","kf = KFold(n_splits=k, shuffle=True)\n","```\n","\n","where the argument `n_splits=k` specifies the number of subsets to use. On the other hand, the argument `shuffle` is set to false by default, but it is generally a good practice to shuffle the data for cross validation (it is usual that, during collection and storage, data of a similar type is stored adjacently and this would lead to some learning bias when training the tree). Complete information about this function is available at\n","\n","https://scikit-learn.org/stable/modules/generated/sklearn.model_selection.KFold.html\n","\n","Now, we will the `KFold` function to split the dataset of galaxies into k−1 training subsets and one remaining test subset. The first step is to inizialise the function with, for example, **k=5**. We will also inizialise the decision tree  with a `max_depth=19` (according to our previous results w.r.t. over-fit)."]},{"cell_type":"code","metadata":{"id":"JTULQCiYZ8U-"},"source":["from sklearn.tree import DecisionTreeRegressor\n","from sklearn.model_selection import KFold\n","\n","kf = KFold(n_splits=5, shuffle=True)\n","dec_tree = DecisionTreeRegressor(max_depth=19)\n"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"NbnXoRPQzIwh"},"source":["Using the `.split()` method, applied to the features set, it is possible to generate the **train and test indices**. Note that this defines just the indices corresponding to each subset, but not the subset itself. Thus, the subsets must be defined using those indices. Once the subsets are defined, they are used to train the decision tree and to evaluate its prediction using the median of the differences. \n","\n","The whole process od defining subsets, training the tree and evaluating the prediction must be repeated for for each of the k-iterations. Hence we implement these actions with a `for` loop as follows,\n","\n"]},{"cell_type":"code","metadata":{"id":"X7bp37a9zJ_o"},"source":["# declare an array for predicted redshifts from each iteration\n","all_predictions = np.zeros_like(targets)\n","\n","for train_indices, test_indices in kf.split(features):\n","  train_features, test_features = features[train_indices], features[test_indices]\n","  train_targets, test_targets = targets[train_indices], targets[test_indices]\n","\n","  # Train the decision tree\n","  dec_tree.fit(train_features, train_targets)\n","  \n","  # Predict using the model\n","  predictions = dec_tree.predict(test_features)\n","\n","  # put the predicted values in the all_predictions array defined above\n","  all_predictions[test_indices] = predictions\n","\n","\n","\n","# Evaluate the model using the median of differences of all_predictions\n","eval_dec_tree = ...  \n","eval_dec_tree"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"AVaTPF0fzdLH"},"source":["Once the model is trained and the predictions are calculated, we will compare graphically these predictions with the targets.\n"]},{"cell_type":"code","metadata":{"id":"DpJcoPtNzdme"},"source":["from matplotlib import pyplot as plt\n","%matplotlib inline\n","\n","# plot the results to see how well our model looks\n","plt.figure()\n","plt.scatter(targets, all_predictions, s=0.4)\n","plt.xlim((0, targets.max()))\n","plt.ylim((0, predictions.max()))\n","plt.xlabel('Measured Redshift')\n","plt.ylabel('Predicted Redshift')\n","plt.show()"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"Vs0OIwEX7CcD"},"source":["\n","The above plot should look like the following\n","\n","<center>\n","<img src=\"https://groklearning-cdn.com/modules/SjroKib6Hs5Fqxq53Vxme9/predicted_v_measured.png\" width=450>\n","</center>\n","\n","\n","Note that in the plot of the predicted vs measured redshifts there is a good behavior for many of the galaxies but there are also many outliers (point out of the line)."]},{"cell_type":"markdown","metadata":{"id":"Hpk6m0AiAcui"},"source":["---\n","### Spectral Class\n","The 'spec_class' feature in the dataset involves two values:, b'GALAXY' and b'QSO', which identify galaxies and Quasi-Stellar Objects (QSOs), respectively.\n","\n","**1. Define a function that classifies the samples according to the 'spec_class'.**\n","\n","**2. How many galaxies and how many QSOs are there in the dataset?**\n"]},{"cell_type":"markdown","metadata":{"id":"jUa4TMPuAyqc"},"source":["**3. Calculate the median of the differences for galaxies and QSOs. What are the maximum values of these differences for each class of objects?**\n","\n","\n","Galaxies are not as bright as QSOs, so they become too faint to be detected with SDSS at redshifts greater than 0.4. This creates a measurement bias.\n","\n","**4. Make a plot of the median of differences vs. meaasured redshift for all the objects in the dataset, using one color for galaxies and other color for QSOs.**\n"]},{"cell_type":"markdown","metadata":{"id":"FNehsBLLFWUH"},"source":["Now, you will plot again predicted vs measured redshifts, including a color for galaxies and other color for QSOs. The result will look like the following plot\n","\n","<center>\n","<img src=\"https://groklearning-cdn.com/modules/ovFSymwFkqBPAcjnbSUxLG/predicted_actual_qso.png\" width=450>\n","</center>\n","\n","**5. Reproduce the above plot**"]}]}